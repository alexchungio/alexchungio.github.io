# 环视鱼眼感知

## 简述

### 环视感知系统

环视鱼眼系统用于近距离（near-filed）感知。如下图所示，一个典型的自动驾驶环视感知系统，包含位于自车前后左右的的四个鱼眼摄像头组成。每个用于近距离感知的鱼眼相机的视野范围均超过180度，使得由四个鱼眼相机组成的系统足够去覆盖车辆周围180度的区域。

![image-20241102114956337](../graph/surround_view_system.png)



## 相机模型

在实际中，由于制造精度、镜头曲面和装配偏差等原因，导致图像产生畸变。主要表现为径向畸变（radial distortion）和切向畸变（tangential distortion）两种。

鱼眼相机具有较大的径向畸变，感知系统必须要考虑这种相机系统固有的图像畸变。

### 径向畸变

径向畸变指的是沿着透镜半径方向分布的畸变，原因是远离透镜中心的区域比透镜中心光线更弯曲，表现为成像时直线会变弯曲。

![distortion_examples](../graph/distortion_examples.png)

径向畸变模型

$$\begin{aligned}
x'= x(1+k_1r^2+k_2r^4+k_3r^6) \\
y'= y(1+k_1r^2+k_2r^4+k_3r^6) \\
\end{aligned}$$

其中，$r$表示原始点到中心点的距离；$x'$和$y'$分别表示畸变后的距离；$k_1$、$k_2$、$k_3$表示畸变系数

### 切向畸变

切向畸变是指装备时透镜平面与传感器成像平面不平行造成的畸变。切向畸变主要表现为图像的倾斜或偏移。

切向畸变模型

$$\begin{aligned}
x'= x+[2p_1xy+p_2(r^2+2x^2)] \\
y'= y+[2p_1(r^2+2y^2)+2p_2xy]\\
\end{aligned}$$

其中，$(x,y)$是原始坐标；$(x',y')$是切向畸变后的坐标；$p_1$和$p_2$是切向畸变系数；$r$表示原始点到中心点的距离。

### opencv 实现

![image-20251110202453672](../graph/image-20251110202453672.png)

Opencv 针对普通相机和鱼眼相机使用了两种畸变模型。

* 普通相机模型

  普通相机模型，利用径向畸变参数和切向畸变参数构建相机模型，对应的畸变参数和排雷顺序为$(k_1,k_2,p_1,p_2[,k3[k_4,k_5,k6]])$，

  其中，$k_1, k_2,k_3,k_4,k_5,k_6$为径向畸变参数，$p_1,p_2$为切向畸变参数。

  * 标定接口

    `cv::calibrateCamera`

  * 去畸变接口

    `cv::undistort`

* 鱼眼相机模型

  鱼眼模型，基于**Kannala-Brandt**模型，直接利用角度$\theta$计算从相机坐标到虚拟投影球面的坐标。

  鱼眼畸变模型如下

  假设**相机坐标系**中点P的坐标为$(x,y,z)$，根据小孔投影(pinhole projection)原理，可以得到点P在**成像平面**的无畸变投影点坐标$(a,b)$

  其中小孔相机模型的投影公式如下

  $$\begin{aligned}
  a=\frac{x}{z}，b=\frac{y}{z}
  \end{aligned}$$

  容易得到，点$(a,b)$到光轴的距离$r$，公式如下

  $$r^2=a^2+b^2$$

  进一步可以得到投影角度$\theta$，此为非畸变的投影角度，公式如下

  $$\theta=arctan(r)$$

  鱼眼畸变会引入非线形的投影角度，其中畸变角度$\theta_d$用一个多项式来描述，得到**鱼眼畸变模型**如下

  $$r_d = \theta(1+k_1\theta^2+k_2\theta^4+k_3\theta^6+k_4\theta^8)$$

  进一步，由于成像平面远小于焦距，即$\theta_d \to 0$, 容易得
  $$
  r_d=f tan\theta_d \approx \theta_d
  $$
  由于 $\theta_d$趋近与0,
  
  **其中$\theta$表示无畸变的投影角度；$k_1,k_2,k_3,k_4$表示鱼眼径向畸变系数，描述鱼眼镜头的畸变程度。**

  **成像平面畸变后的投影点坐标**$(x'，y')$通过畸变角度$\theta_d$进行缩放得到

  $$\begin{aligned}
  x'=\left(\frac{\theta_d}{r}\right)a，b=\left(\frac{\theta_d}{r}\right){b}
  \end{aligned}$$
  
  最后，将畸变后的坐标$(x'y')$转换到**图像坐标系**的像素坐标$(u,v)$,公式如下
  
  $$\begin{aligned}
  u=f_xx'+c_x \\
  y'= f_yy'+c_y\\
  \end{aligned}$$

  其中$f_x,f_y$表示水平方向和垂直方向的焦距；$c_x,c_y$表示主点坐标，表示图像的中心位置。

  * 标定接口

    `fisheye::calibrate`
  
  * 去畸变接口
  
    `cv::fisheye::undistortImage`
  
    `cv::fisheye::undistortPoints`

## 鱼眼成像原理

![image-20241102150920780](../graph/fisheye_camera.png)

理论上，针孔相机视场角FOV(Field-Of-View)是180度，但是由于孔径大小和成像尺寸的限制，普通针孔相机的视角一般很难超过80度。**鱼眼透镜，由于折射(refaraction)，视场角可以大幅增加到190度**，如上图所示。

鱼眼相机的优势带来的副作用就是，鱼眼相机相比其他针孔相机具有较大的径向畸变，这对感知任务会造成很大挑战。

## 代码实现

### 投影

```python
def get_distort_fisheye(x_norm, y_norm, D):
    '''
    get r_dist gradient function
    fisheye distort model: r = theta * (1 + k1*theta2 + k2*theta4 + k3*theta6 + k4*theta8)
    '''
    k_1, k_2, k_3, k_4 = D
    # # calculate distance to zero pint
    r = np.sqrt(x_norm  2 + y_norm  2)
    # # calculate theta(from optical axis to the point)
    theta = np.arctan(r)
    # theta = np.pi - theta  # !!!

    theta_2 = theta * theta
    theta_4 = theta_2 * theta_2
    theta_6 = theta_4 * theta_2
    theta_8 = theta_6 * theta_2
    theta_d = theta * (1 + k_1*theta_2 + k_2*theta_4 + k_3*theta_6 + k_4*theta_8)

    # r<0, maintain origin direction
    r[r == 0] = 1e-8
    scale = theta_d / r
    x_dist = x_norm * scale
    y_dist = y_norm * scale

    return x_dist, y_dist


def get_distort_common(x_norm, y_norm, D):
    '''

    '''
    k_1, k_2, k_3 = D[0], D[1], 0 if len(D) < 5 else D[4]  # radial distort and
    p_1, p_2 = D[2], D[3]  # tangential distort param

    r_2 = x_norm  2 + y_norm  2
    r_4 = r_2 * r_2
    r_6 = r_4 * r_2

    # calculate radial param
    cdist = 1.0 + k_1 * r_2 + k_2 * r_4 + k_3 * r_6

    x_dist = x_norm * cdist + 2 * p_1 * x_norm * y_norm + p_2 * (r_2 + 2 * x_norm ** 2)
    y_dist = y_norm * cdist + 2 * p_2 * x_norm * y_norm + p_1 * (r_2 + 2 * y_norm ** 2)

    return x_dist, y_dist


def lidar2cam(points, T):
    """
    convert point from lidar-coord to camara-coord
    Args:
        points: (N,3)
        T: (4,4)

    Returns:

    """

    points_cam = copy.deepcopy(points)

    points_cam = points_cam.T
    one_array = np.ones((1, points_cam.shape[1]), dtype=np.float64)
    points_cam = np.vstack((points_cam, one_array))
    points_cam = T @ points_cam
    points_cam = points_cam.T[:, :3]

    return points_cam


def cam2pixel(points, K, D):
    """
    convert point from camera coord to pixel coord
    Args:
        point:
        K: 4
        D: 4x4

    Returns:

    """
    points_cam = points.copy()

    # cal normalize coord
    x_norm = points_cam[..., 0] / abs(points_cam[..., 2])  # x/z
    y_norm = points_cam[..., 1] / abs(points_cam[..., 2])  # y/z
    #
    # # calculate distort param
    x_dist, y_dist = get_distort_fisheye(x_norm, y_norm, D)
    #
    # # convert to image-coord with intra-param
    fx, cu, fy, cv = K[0, 0], K[0, 2], K[1, 1], K[1, 2]
    u = fx * x_dist + cu
    v = fy * y_dist + cv
    # u = fx * x_norm + cu
    # v = fy * y_norm + cv
    # generate pixel
    pixels = np.hstack((u.reshape(-1, 1), v.reshape(-1, 1)))

    return pixels


def project_fisheye(points, labels, K, D, T, resolution):
    """
    project pcd from lidar to pixel
    Args:
        points:
        labels:
        K: (3,3)
        D: (4,)
        T: (4,4)
        resolution:

    Returns:

    """
    points_cam = lidar2cam(points, T)

    # filter behind point of camera (restrict with fov)
    fov_mask = points_cam[:, 2] > 0
    points_cam = points_cam[fov_mask]
    labels = labels[fov_mask]

    # cam to pixel
    pixels = cam2pixel(points_cam, K=K, D=D)

    # filter point with image shape
    valid = (pixels[:, 0] >= 0) & (pixels[:, 0] < resolution[1]) & (pixels[:, 1] >= 0) & (
            pixels[:, 1] < resolution[0])

    fov_pixel = pixels[valid].astype(np.int32)
    fov_label = labels[valid].astype(np.int32)

    return fov_pixel, fov_label

```

### 反投影

```python
def back_project_fisheye():
  pass
```



## 参考资料

* Surround-view Fisheye Camera Perception for Automated Driving: Overview, Survey & Challenges
* https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html
* https://docs.opencv.org/4.x/db/d58/group__calib3d__fisheye.html#ga167df4b00a6fd55287ba829fbf9913b9

* https://blog.csdn.net/qq_25458977/article/details/109991695

* https://www.zhihu.com/question/466642002/answer/2466199557