# LSS 论文总结

## 背景

在自动驾驶或者机器人领域，需要从摄像头获取的二维图像中提取三维信息，特别是从任意配置的摄像头中获取三维信息。从二维图像中的点映射回3D空间中，即反投影过程（back-projection）,其核心是通过相机内参和外参建立几何映射关系。

反投影得到的是从相机光心出发经过图像点的射线，*而非唯一的3D坐标*。需要依赖深度值z，去计算具体的3D位置坐标。

### 概述

LSS(Lift-Splat-Shoot) 范式的本质是三步：第一步，通过2D特征和每个像素的深度估计，形成2.5D的**相机（camera）坐标系**的视锥点云/视锥特征；第二步，通过相机内外参，将视锥点云从相机坐标系转换到**自车（ego）坐标系**，形成3D空间的**稠密点云**；第三步，构建**体素空间**（点云空间的稀疏化表示），通过`voxel_pooling`对同一网格的所有点云进行求和池化，形成BEV特征。

具体论文中， Lift 对应第一步，Splat 包含第二步和第三步， 而Shoot，表示在BEV特征图上执行下游任务。

## 关键点

### Lift(提升)

Lift的作用是将单目（monocular）图像的2D特征提升到3D空间，生成视锥点云（Frustum Point Cloud）

融合多个单目相机的难度在于，需要依赖深度信息才能将像素投影到参考坐标系（自车/世界坐标系），但是对于二维图像每个像素的“深度”本质上是模糊的。

#### 执行步骤

* 生成视锥点云

  Lift，为每个像素添加depth信息时，通过为**每个像素估计一个深度分布（每个像素在不同深度的概率）**，*通过离散深度采样代替显示深度预测，避免误差累计*，将2D的图像的点“提升”到假设的3D空间中的点云。

  生成的3D点云包含所有可能的三维坐标分布，三维坐标的深度分布通过BEV空间的具体的监督任务进行学习。

* 特征外积增强

​		略

### Splat(泼洒)

Splat，将多个相机通过Lift中“提升”得到的3D点云投影到统一的BEV空间，生成BEV特征。

#### 执行步骤

* 坐标系变换

  将图像坐标系的点云转换到自车坐标系

* 融合不同摄像头点云

  融合不同摄像头的点云信息，生成一个稠密的三维表示

* 体素池化（voxel pooling）
  * 构建固定大小的体素/网格空间，为每个点分配王哥索引
  * 累计池化，通过网格索引聚合特征，稀疏化点云

### Shoot(预测)

Shoot，在BEV特征图上执行下游任务，如OCC、3D-OD或轨迹预测等。

#### 执行步骤

* BEV特征编码
* 任务头设计

## 参考资料

* [LSS论文与代码详解-掘金](https://juejin.cn/post/7385375139305668627)
* https://zhuanlan.zhihu.com/p/567926611
* https://zhuanlan.zhihu.com/p/668846159
* https://zhuanlan.zhihu.com/p/6144337348



