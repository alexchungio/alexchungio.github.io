# 多机多卡分布式训练



### 原理

多机多卡训练需要配置的关键参数如下

* nproc_per_node: 每个节点对应的卡数
* nnodes：当前训练集群总的节点数。比如两台机器，对应的nnodes=2
* node_rank: 当前节点的优先级排序。**主节点（master）对应的 node_rank=0**，其他从节点依次从小到大排序，分别对应优先级从高到低。
* master_addr：主节点通信地址。对于单机单卡训练，master_addr 对应本机的IP地址；**对于多机多卡训练，从节点master_addr必须与主节点master_addr一致**。
* master_port：主节点通信端口。对于单机单卡训练，master_port 对应本机任意空闲端口；**对于多机多卡训练，从节点master_port必须与主节点master_port端口号保持相同**。

### 实现

以2机8卡训练为例

* 主机启动脚本

  ```shell
  # dist_train_0.sh
  CONFIG=./plugin_geely/configs/parking/flashocc_henet_lss_lite_parking_11110_1_0_balance_dice_0_2_ce_visible_mask_4d_bs_10x8x2_f_3.py
  STAGE=float
  
  GPUS=8
  NNODES=2
  NODE_RANK=0
  MASTER_ADDR=10.244.60.52  #hostname -i
  PORT=29506
  
  PYTHONPATH="$(dirname $0)/../plugin_geely":$PYTHONPATH 
  CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 torchrun \
  --nproc_per_node=$GPUS \
  --nnodes=$NNODES \
  --node_rank=$NODE_RANK \
  --master_addr=$MASTER_ADDR \
  --master_port=$PORT \
  ./tools/train.py \
  --config ${CONFIG} \
  --stage ${STAGE} \
  --launcher torch
  
   python3 ./gpu_full.py 0,1,2,3,4,5,6,7
  ```

  

* 从机启动脚本

  ```shell
  # dist_train_0.sh
  CONFIG=./plugin_geely/configs/parking/flashocc_henet_lss_lite_parking_11110_1_0_balance_dice_0_2_ce_visible_mask_4d_bs_10x8x2_f_3.py
  STAGE=float
  
  GPUS=8
  NNODES=2
  NODE_RANK=1
  MASTER_ADDR=10.244.60.52  #hostname -i
  PORT=29506
  
  PYTHONPATH="$(dirname $0)/../plugin_geely":$PYTHONPATH 
  CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7 torchrun \
  --nproc_per_node=$GPUS \
  --nnodes=$NNODES \
  --node_rank=$NODE_RANK \
  --master_addr=$MASTER_ADDR \
  --master_port=$PORT \
  ./tools/train.py \
  --config ${CONFIG} \
  --stage ${STAGE} \
  --launcher torch
  
   python3 ./gpu_full.py 0,1,2,3,4,5,6,7
  ```

* 操作步骤

  1. 在主节点启动训练脚本 `dist_train_0.sh`
  2. 在从节点启动训练脚本 `dist_train_1.sh`

  