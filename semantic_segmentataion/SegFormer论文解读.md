# SegFormer 论文总结

## 关键点

### 层级的transformer 编码器

#### 层级的特征表示

生成类似CNN的，分辨率从1/4到1/16的多层特征表示。提供高分辨率的粗糙特征和低分辨率的精细特征。

#### 重叠Patch嵌入

为了保存patch周围的局部连续性，使用重叠patch嵌入，保留更多的局部信息。

#### 高效自注意力

通过将特征图序列长度减少4倍，显著降低计算复杂度。

#### Mix-FFN

论文证明，对于密集预测任务，显示位置编码是没必要的。

在FFN，引入3x3的深度可分离卷积传递位置信息。

### 轻量化的MLP 解码器

#### 解码器过程

* 对每个尺度特征应用独立的MLP层统一通道维度

* 使用上采样将所有特征调整到1/4输入分辨率

* 级联所有特征形成统一表示
* 融合级联后的特征表示

#### 设计动机

轻量化解码器的关键是因为，论文的层级transformer encoder 比传统CNN 有更大的有效感受野。

### 无位置编码器设计

#### 动机

* VIT 中的位置编码在处理不同尺寸的输入时，需要对位置编码进行差值。无位置编码可以避免这种差值导致的性能下降。

* 移除位置编码，模型可以自适应于不同的输入分辨率

#### 位置编码的隐式获取

**重叠式Patch嵌入**

- 使用卷积而非简单分块，保留了局部邻域信息
- 重叠设计使相邻区域之间共享信息，有助于保持局部空间连续性

**层次化Transformer编码器**：

- 多尺度特征自然包含了位置相关的信息
- 不同尺度特征的组合隐含编码了位置关系

**Mix-FFN**：

- 在前馈网络中加入3×3深度可分离卷积，显著增强了位置信息的传递

